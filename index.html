<!DOCTYPE html>
<html lang="kk">
<head>
  <meta charset="utf-8" />
  <title>AI Interview Simulator</title>
  <style>
    body{font-family:Arial,sans-serif;margin:30px}
    button{font-size:18px;padding:10px 16px}
    #status{margin-top:10px}
    pre{background:#f4f4f4;padding:10px;border-radius:6px}
  </style>
</head>
<body>
  <h2>üé§ AI Interview Simulator (push-to-talk)</h2>

  <p id="question">–°“±—Ä–∞“õ –∂“Ø–∫—Ç–µ–ª—É–¥–µ...</p>

  <button id="micBtn">üéôÔ∏è “∞—Å—Ç–∞“£—ã–∑ –∂”ô–Ω–µ –∂–∞—É–∞–ø –±–µ—Ä—ñ“£—ñ–∑</button>
  <div id="status">–°—Ç–∞—Ç—É—Å: –∫“Ø—Ç—ñ–ø —Ç“±—Ä...</div>

  <h3>–ù”ô—Ç–∏–∂–µ (—Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç)</h3>
  <pre id="transcript">‚Äî</pre>

  <h3>AI –∫–µ—Ä—ñ –±–∞–π–ª–∞–Ω—ã—Å</h3>
  <pre id="feedback">‚Äî</pre>

<script>
const questions = [
  "–°—ñ–∑–¥—ñ“£ –∂–æ–±–∞“£—ã–∑–¥—ã“£ –±–∞—Å—Ç—ã “õ“±–Ω–¥—ã–ª—ã“ì—ã “õ–∞–Ω–¥–∞–π?",
  "–ù–∞—Ä—ã“õ—Ç–∞“ì—ã –±”ô—Å–µ–∫–µ–ª–µ—Å—Ç–µ—Ä–¥–µ–Ω “õ–∞–Ω–¥–∞–π –∞–π—ã—Ä–º–∞—à—ã–ª—ã“ì—ã“£—ã–∑ –±–∞—Ä?",
  "“ö–∏—ã–Ω –∂–∞“ì–¥–∞–π–¥–∞ –∂–æ–±–∞–Ω—ã “õ–∞–ª–∞–π –¥–∞–º—ã—Ç–∞—Å—ã–∑?",
  "–ö–æ–º–∞–Ω–¥–∞“£—ã–∑–¥—ã“£ –º—ã“õ—Ç—ã –∂”ô–Ω–µ ”ô–ª—Å—ñ–∑ –∂–∞“õ—Ç–∞—Ä—ã “õ–∞–Ω–¥–∞–π?",
  "–ê–ª“ì–∞—à“õ—ã –∂—ã–ª—ã “õ–∞–Ω–¥–∞–π –Ω”ô—Ç–∏–∂–µ–≥–µ –∂–µ—Ç–µ—Å—ñ–∑ –¥–µ–ø –æ–π–ª–∞–π—Å—ã–∑?"
];

document.getElementById('question').innerText = questions[Math.floor(Math.random()*questions.length)];

const micBtn = document.getElementById('micBtn');
const status = document.getElementById('status');
const transcriptEl = document.getElementById('transcript');
const feedbackEl = document.getElementById('feedback');

let mediaRecorder;
let audioChunks = [];

async function initStream(){
  try {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    mediaRecorder = new MediaRecorder(stream);

    mediaRecorder.ondataavailable = e => {
      if(e.data && e.data.size > 0) audioChunks.push(e.data);
    };

    mediaRecorder.onstop = async () => {
      status.innerText = '–ñ–∞–∑–±–∞ –¥–∞–π—ã–Ω, —Å–µ—Ä–≤–µ—Ä–≥–µ –∂—ñ–±–µ—Ä—ñ–ª—É–¥–µ...';
      const blob = new Blob(audioChunks, { type: 'audio/webm' });
      audioChunks = [];

      const fd = new FormData();
      fd.append('audio', blob, 'recording.webm');

      try {
        const res = await fetch('/upload', { method: 'POST', body: fd });
        const data = await res.json();
        if(res.ok){
          transcriptEl.innerText = data.transcript || '(—Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç –∂–æ“õ)';
          feedbackEl.innerText = data.feedback || '(–∫–µ—Ä—ñ –±–∞–π–ª–∞–Ω—ã—Å –∂–æ“õ)';
          status.innerText = '–î–∞–π—ã–Ω.';
        } else {
          transcriptEl.innerText = '(“õ–∞—Ç–µ)';
          feedbackEl.innerText = data.error || JSON.stringify(data);
          status.innerText = '“ö–∞—Ç–µ: —Å–µ—Ä–≤–µ—Ä –∂–∞—É–∞–ø –±–µ—Ä–º–µ–¥—ñ';
        }
      } catch(err){
        status.innerText = '–ñ—ñ–±–µ—Ä—É “õ–∞—Ç–µ—Å—ñ: ' + err.message;
      }
    };
  } catch(err){
    status.innerText = '–ú–∏–∫—Ä–æ—Ñ–æ–Ω“ì–∞ “õ–æ—Å—ã–ª—É “õ–∞—Ç–µ—Å—ñ: ' + err.message;
    micBtn.disabled = true;
  }
}

initStream();

// push-to-talk: mouse (–∂”ô–Ω–µ touch) events
micBtn.onmousedown = () => {
  if(!mediaRecorder) { status.innerText = '–ú–∏–∫—Ä–æ—Ñ–æ–Ω –¥–∞–π—ã–Ω –µ–º–µ—Å'; return; }
  audioChunks = [];
  mediaRecorder.start();
  status.innerText = '‚úÖ –ñ–∞–∑—ã–ø –∂–∞—Ç—ã—Ä... (–±–∞—Ç—ã—Ä–º–∞–Ω—ã –±–æ—Å–∞—Ç“õ–∞–Ω—à–∞ —Å”©–π–ª–µ“£—ñ–∑)';
};
micBtn.onmouseup = () => {
  if(mediaRecorder && mediaRecorder.state !== 'inactive') mediaRecorder.stop();
};
// touch support
micBtn.ontouchstart = () => { if(mediaRecorder) { audioChunks=[]; mediaRecorder.start(); status.innerText='–ñ–∞–∑—É...'; } };
micBtn.ontouchend = () => { if(mediaRecorder && mediaRecorder.state!=='inactive') mediaRecorder.stop(); };
</script>
</body>
</html>
